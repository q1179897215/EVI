{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 6, 2):\n",
    "    print(i)\n",
    "    print(i+1)\n",
    "print(i+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 95, 1])\n",
      "torch.Size([3, 1, 5])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 95, 5])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "def outer_product(x, y):\n",
    "    \"\"\"\n",
    "    x: [batch_size, x_dim]\n",
    "    y: [batch_size, y_dim]\n",
    "    \"\"\"\n",
    "    x = x.unsqueeze(2)\n",
    "    y = y.unsqueeze(1)\n",
    "    out = x * y\n",
    "    out = out.reshape(x.size(0), -1)\n",
    "    return out\n",
    "x = torch.randn(3, 95)\n",
    "y = torch.randn(3, 5)\n",
    "outer_product(x, y).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.7792609112148328"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# caculate the improvement percentage\n",
    "import numpy as np\n",
    "def cac_improvement(old, new):\n",
    "    return (new - old) / old * 100\n",
    "\n",
    "new = np.array([0.6802,0.8008,0.8140,0.8136,0.8057,0.8292])\n",
    "old = np.array([0.6711,0.7865,0.8032,0.7889,0.7685,0.8211])\n",
    "new = np.array([0.0321,0.1037,0.0939,0.0976,0.1401, 0.1621])\n",
    "old = np.array([0.0330,0.1116,0.0951,0.0997,0.1425,0.1651])\n",
    "cac_improvement(old, new).mean()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.3127],\n",
      "        [-1.6860],\n",
      "        [-0.7457]])\n",
      "tensor([[ 0.3166,  0.2711, -0.7014,  0.2126,  0.2096],\n",
      "        [ 1.7651,  1.0390,  0.8166,  1.9816,  0.0379],\n",
      "        [ 1.3109,  0.7982,  0.3406,  1.4269,  0.0918]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "x  = torch.randn(3, 1)\n",
    "layer = nn.Linear(1, 5)\n",
    "y = layer(x)\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 7660.5166\n",
      "Epoch [2/10], Loss: 6921.8589\n",
      "Epoch [3/10], Loss: 6487.2461\n",
      "Epoch [4/10], Loss: 6202.7012\n",
      "Epoch [5/10], Loss: 6017.5674\n",
      "Epoch [6/10], Loss: 5913.8203\n",
      "Epoch [7/10], Loss: 5861.7832\n",
      "Epoch [8/10], Loss: 5835.8735\n",
      "Epoch [9/10], Loss: 5821.7402\n",
      "Epoch [10/10], Loss: 5813.2549\n",
      "prediction mean: 0.5115\n",
      "positive sample: 51\n",
      "negative sample: 53\n",
      "actual mean: 0.4904\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the dataset from online \n",
    "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv'\n",
    "# url = './data_sample/diabetes.csv'\n",
    "data = pd.read_csv(url, header=None)\n",
    "# oversample the negative samples\n",
    "sample_ratio = 0.5\n",
    "negative_sample_num = round(len(data[data[8] == 0]) * sample_ratio)\n",
    "data = pd.concat([data[data[8] == 1], data[data[8] == 0].sample(negative_sample_num, replace=True)])\n",
    "# Separate the features and target variable\n",
    "label = 8\n",
    "X = data.drop(label, axis=1)\n",
    "y = data[label]\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=46)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Convert the data to PyTorch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train.values, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test.values, dtype=torch.float32)\n",
    "class Netron(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Netron, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "# Set the random seed for reproducibility\n",
    "torch.manual_seed(4)\n",
    "\n",
    "# Initialize the model\n",
    "model = Netron(input_dim=X_train.shape[1])\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.BCELoss(reduction='none')\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 10\n",
    "batch_size = 32\n",
    "num_batches = len(X_train) // batch_size\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in range(num_batches):\n",
    "        # Get the batch data\n",
    "        start_idx = batch * batch_size\n",
    "        end_idx = (batch + 1) * batch_size\n",
    "        batch_X = X_train[start_idx:end_idx]\n",
    "        batch_y = y_train[start_idx:end_idx]\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y.unsqueeze(1))\n",
    "        # caculate the loss of positive samples\n",
    "        loss = loss*y_train + (1-y_train)*loss\n",
    "        loss = loss.sum()\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Print the loss for each epoch\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    y_pred = model(X_test)\n",
    "    y_pred = sample_ratio*y_pred/(1-(1-sample_ratio)*y_pred)\n",
    "    # y_pred = (y_pred >= 0.5).float()\n",
    "\n",
    "    # accuracy = (y_pred == y_test.unsqueeze(1)).sum().item() / len(y_test)\n",
    "    # print(f'Test Accuracy: {accuracy:.4f}')\n",
    "    # caculate the mean of y_pred[y=1]\n",
    "    print(f'prediction mean: {y_pred[y_test==1].mean():.4f}')\n",
    "    print(f'positive sample: {len(y_test[y_test==1])}')\n",
    "    print(f'negative sample: {len(y_test[y_test==0])}')\n",
    "    print(f'actual mean: {y_test.mean():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_pred[y_test==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Squeeze_72:0\", shape=(100, 48), dtype=float32)\n",
      "[[[0.10409561 0.6774731  0.21843123]\n",
      "  [0.32537004 0.2582363  0.4163937 ]\n",
      "  [0.25499988 0.14607085 0.5989293 ]\n",
      "  ...\n",
      "  [0.25034818 0.17410088 0.575551  ]\n",
      "  [0.28291398 0.11199827 0.6050877 ]\n",
      "  [0.28036767 0.37287846 0.34675387]]\n",
      "\n",
      " [[0.8757716  0.00406646 0.12016194]\n",
      "  [0.14758863 0.23786373 0.6145476 ]\n",
      "  [0.43321624 0.2891689  0.27761486]\n",
      "  ...\n",
      "  [0.09620936 0.5757924  0.32799825]\n",
      "  [0.41422153 0.45843616 0.12734237]\n",
      "  [0.53675884 0.17624821 0.2869929 ]]\n",
      "\n",
      " [[0.14462696 0.08422034 0.7711527 ]\n",
      "  [0.13770004 0.5475965  0.3147035 ]\n",
      "  [0.11975987 0.54444075 0.3357994 ]\n",
      "  ...\n",
      "  [0.5229638  0.16491988 0.31211627]\n",
      "  [0.06484465 0.48299566 0.4521597 ]\n",
      "  [0.68803877 0.08180112 0.23016007]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.11332358 0.35908467 0.52759176]\n",
      "  [0.17994204 0.06786871 0.7521893 ]\n",
      "  [0.48757085 0.3269805  0.18544859]\n",
      "  ...\n",
      "  [0.0825779  0.69366515 0.223757  ]\n",
      "  [0.25346154 0.5619587  0.18457976]\n",
      "  [0.15865892 0.1133096  0.72803146]]\n",
      "\n",
      " [[0.0663952  0.91191685 0.02168795]\n",
      "  [0.19589208 0.06562012 0.7384878 ]\n",
      "  [0.66438866 0.19585122 0.13976014]\n",
      "  ...\n",
      "  [0.11635327 0.33555844 0.5480883 ]\n",
      "  [0.2483313  0.4632912  0.2883775 ]\n",
      "  [0.75361323 0.06105494 0.18533187]]\n",
      "\n",
      " [[0.6591941  0.12546226 0.21534358]\n",
      "  [0.39691666 0.549376   0.05370735]\n",
      "  [0.3177524  0.23680598 0.4454416 ]\n",
      "  ...\n",
      "  [0.22154771 0.37273023 0.40572205]\n",
      "  [0.42591146 0.29872233 0.27536622]\n",
      "  [0.19518375 0.75494367 0.04987256]]]\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# create a tensorflow layer with dimension 48-1\n",
    "layer = tf.keras.layers.Dense(1, input_shape=(48,))\n",
    "# create a input of (48,48)\n",
    "input1 = tf.random.normal([100, 48])\n",
    "input2 = tf.random.normal([100, 48])\n",
    "input3= tf.random.normal([100, 48])\n",
    "input4= tf.random.normal([100, 48])\n",
    "experts = [input1, input2, input3]\n",
    "input = tf.concat(experts, axis=1)\n",
    "gate = tf.random.normal([100, 27])\n",
    "gate_out_reshape = tf.reshape(gate, [-1, 9, 3])\n",
    "gate_softmax = tf.nn.softmax(gate_out_reshape)\n",
    "mmoe_mlp_result_input = tf.keras.layers.Concatenate(axis=1)([tf.expand_dims(v,1) for v in experts])\n",
    "mmoe_mlp_result = tf.matmul(gate_softmax, mmoe_mlp_result_input)\n",
    "mlp_shape = mmoe_mlp_result.shape\n",
    "mmoe_mlp_splits = [tf.squeeze(v, 1) for v in tf.split(mmoe_mlp_result, mlp_shape[1], axis=1)]\n",
    "\n",
    "# print the output\n",
    "print(mmoe_mlp_splits[0])\n",
    "#\n",
    "print(tf.keras.backend.eval(gate_softmax))\n",
    "print(len(mmoe_mlp_splits))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'id_mapping_layer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-ba6fac01778a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# ----------- Embedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcate_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"music\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"movie\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"finance\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"game\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"military\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"history\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# [batch_size,1]的string型\"文章分类\"向量\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcate_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mid_mapping_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcate_input\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# string型输入的“文章分类”映射成int型id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# 得到形状=[batch_size,4]的float稠密向量，表示每个“文章分类”的语义\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcate_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0memb_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcate_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'id_mapping_layer' is not defined"
     ]
    }
   ],
   "source": [
    "# ----------- Embedding\n",
    "cate_input = [[\"music\", \"movie\", \"finance\"],[\"game\", \"military\", \"history\"]]  # [batch_size,1]的string型\"文章分类\"向量\n",
    "cate_ids = id_mapping_layer(cate_input)  # string型输入的“文章分类”映射成int型id\n",
    "# 得到形状=[batch_size,4]的float稠密向量，表示每个“文章分类”的语义\n",
    "cate_embeddings = emb_layer(cate_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "y_label = np.array([10, 4, 7, 2, 21, 7, 50, 8, 8, 2, 2, 2, 2, 2, 2, 2]) * 0.01\n",
    "y_pred = np.array([10, 4, 7, 2, 21, 7, 50, 8, 8, 2, 2, 2, 2, 2, 2, 2]) * 0.01 + 0.001\n",
    "# convert numpy array to tensor\n",
    "y_label = tf.convert_to_tensor(y_label, dtype=tf.float32)\n",
    "y_pred = tf.convert_to_tensor(y_pred, dtype=tf.float32)\n",
    "# stack y_label with 1-y_label\n",
    "y_label_stack = tf.stack([y_label, 1 - y_label], axis=1)\n",
    "y_pred_stack = tf.stack([y_pred, 1 - y_pred], axis=1)\n",
    "\n",
    "# print(tf.keras.backend.eval(y_label))\n",
    "# print(tf.keras.backend.eval(y_pred))\n",
    "kl = tf.keras.losses.KLDivergence(reduction=\"sum\")\n",
    "kl_loss = kl(y_label, y_pred)\n",
    "kl_loss_stack = kl(y_label_stack, y_pred_stack)\n",
    "print(tf.keras.backend.eval(kl_loss))\n",
    "print(tf.keras.backend.eval(kl_loss_stack))\n",
    "\n",
    "# # print y_label's value\n",
    "# print(y_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Sum_11:0' shape=(10,) dtype=float32>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "y_pred = np.random.randn(10, 5)\n",
    "y_label = np.random.randn(10, 5)\n",
    "pctr = np.random.randn(10)\n",
    "# convert numpy array to tensor\n",
    "y_pred = tf.convert_to_tensor(y_pred, dtype=tf.float32)\n",
    "y_label  = tf.convert_to_tensor(y_label, dtype=tf.float32)\n",
    "pctr = tf.convert_to_tensor(pctr, dtype=tf.float32)\n",
    "multitask_loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=y_label, logits=y_pred)\n",
    "mask = tf.cast(tf.not_equal(y_label, 0), tf.float32)\n",
    "masked_loss = tf.multiply(multitask_loss, mask)\n",
    "loss = tf.reduce_sum(masked_loss, axis=1)\n",
    "loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'>\n",
      "(1, 2, 'hello world')\n",
      "<class 'dict'>\n",
      "{'a': 4, 'b': 6, 'c': 'oo', 'd': []}\n"
     ]
    }
   ],
   "source": [
    "def func1(*args,**kwargs):\n",
    "\tprint(type(args))\n",
    "\tprint(args)\n",
    "\tprint(type(kwargs))\n",
    "\tprint(kwargs)\n",
    "func1(1,2,'hello world',a=4,b=6,c='oo',d=[])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>fr/ctcvr_auc</th>\n",
       "      <th>fr/ctr_auc</th>\n",
       "      <th>fr/cvr_auc</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DESCM_Embedding+Basic_Loss</td>\n",
       "      <td>0.8593</td>\n",
       "      <td>0.7144</td>\n",
       "      <td>0.7961</td>\n",
       "      <td>fr</td>\n",
       "      <td>Basic_Loss</td>\n",
       "      <td>DESCM_Embedding</td>\n",
       "      <td>DESCM_Embedding+Basic_Loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ESCM+Basic_Loss</td>\n",
       "      <td>0.8438</td>\n",
       "      <td>0.7148</td>\n",
       "      <td>0.7782</td>\n",
       "      <td>fr</td>\n",
       "      <td>Basic_Loss</td>\n",
       "      <td>ESCM</td>\n",
       "      <td>ESCM+Basic_Loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DESCM_Embedding+Entire_Space_Basic_Loss</td>\n",
       "      <td>0.8392</td>\n",
       "      <td>0.7140</td>\n",
       "      <td>0.7370</td>\n",
       "      <td>fr</td>\n",
       "      <td>Entire_Space_Basic_Loss</td>\n",
       "      <td>DESCM_Embedding</td>\n",
       "      <td>DESCM_Embedding+Entire_Space_Basic_Loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DESCM_Embedding+DR_Loss</td>\n",
       "      <td>0.8610</td>\n",
       "      <td>0.6874</td>\n",
       "      <td>0.7919</td>\n",
       "      <td>fr</td>\n",
       "      <td>DR_Loss</td>\n",
       "      <td>DESCM_Embedding</td>\n",
       "      <td>DESCM_Embedding+DR_Loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DESCM_Embedding+IPW_Loss</td>\n",
       "      <td>0.8634</td>\n",
       "      <td>0.6839</td>\n",
       "      <td>0.7920</td>\n",
       "      <td>fr</td>\n",
       "      <td>IPW_Loss</td>\n",
       "      <td>DESCM_Embedding</td>\n",
       "      <td>DESCM_Embedding+IPW_Loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ESCM+Entire_Space_Basic_Loss</td>\n",
       "      <td>0.8172</td>\n",
       "      <td>0.7153</td>\n",
       "      <td>0.6881</td>\n",
       "      <td>fr</td>\n",
       "      <td>Entire_Space_Basic_Loss</td>\n",
       "      <td>ESCM</td>\n",
       "      <td>ESCM+Entire_Space_Basic_Loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ESCM+DR_Loss</td>\n",
       "      <td>0.8687</td>\n",
       "      <td>0.6853</td>\n",
       "      <td>0.7927</td>\n",
       "      <td>fr</td>\n",
       "      <td>DR_Loss</td>\n",
       "      <td>ESCM</td>\n",
       "      <td>ESCM+DR_Loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ESCM+IPW_Loss</td>\n",
       "      <td>0.8707</td>\n",
       "      <td>0.6817</td>\n",
       "      <td>0.7919</td>\n",
       "      <td>fr</td>\n",
       "      <td>IPW_Loss</td>\n",
       "      <td>ESCM</td>\n",
       "      <td>ESCM+IPW_Loss</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Method  fr/ctcvr_auc  fr/ctr_auc  \\\n",
       "0               DESCM_Embedding+Basic_Loss        0.8593      0.7144   \n",
       "1                          ESCM+Basic_Loss        0.8438      0.7148   \n",
       "2  DESCM_Embedding+Entire_Space_Basic_Loss        0.8392      0.7140   \n",
       "3                  DESCM_Embedding+DR_Loss        0.8610      0.6874   \n",
       "4                 DESCM_Embedding+IPW_Loss        0.8634      0.6839   \n",
       "5             ESCM+Entire_Space_Basic_Loss        0.8172      0.7153   \n",
       "6                             ESCM+DR_Loss        0.8687      0.6853   \n",
       "7                            ESCM+IPW_Loss        0.8707      0.6817   \n",
       "\n",
       "   fr/cvr_auc   0                        1                2  \\\n",
       "0      0.7961  fr               Basic_Loss  DESCM_Embedding   \n",
       "1      0.7782  fr               Basic_Loss             ESCM   \n",
       "2      0.7370  fr  Entire_Space_Basic_Loss  DESCM_Embedding   \n",
       "3      0.7919  fr                  DR_Loss  DESCM_Embedding   \n",
       "4      0.7920  fr                 IPW_Loss  DESCM_Embedding   \n",
       "5      0.6881  fr  Entire_Space_Basic_Loss             ESCM   \n",
       "6      0.7927  fr                  DR_Loss             ESCM   \n",
       "7      0.7919  fr                 IPW_Loss             ESCM   \n",
       "\n",
       "                                    method  \n",
       "0               DESCM_Embedding+Basic_Loss  \n",
       "1                          ESCM+Basic_Loss  \n",
       "2  DESCM_Embedding+Entire_Space_Basic_Loss  \n",
       "3                  DESCM_Embedding+DR_Loss  \n",
       "4                 DESCM_Embedding+IPW_Loss  \n",
       "5             ESCM+Entire_Space_Basic_Loss  \n",
       "6                             ESCM+DR_Loss  \n",
       "7                            ESCM+IPW_Loss  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "impory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'b', 'd', 'd', 's']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 'dbdsa'\n",
    "sorted(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "class CrossNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, layer_num=3):\n",
    "        super(CrossNetwork, self).__init__()\n",
    "        self.cross_layers = nn.ModuleList([nn.Linear(input_dim, 1) for _ in range(layer_num)])\n",
    "\n",
    "    def forward(self, x, x0):\n",
    "        for layer in self.cross_layers:\n",
    "            x = x0 * layer(x) + x\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.46465401])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "best = np.array([0.6789])\n",
    "sub = np.array([0.6691])\n",
    "def caculate_improvement(best, sub):\n",
    "    return (best-sub)/sub*100\n",
    "caculate_improvement(best, sub)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5582 0.6655 0.6665 0.6419 0.678  0.6248]\n",
      " [0.5378 0.6559 0.6642 0.643  0.6723 0.6194]\n",
      " [0.6206 0.7144 0.7158 0.689  0.7129 0.6451]\n",
      " [0.5621 0.6676 0.6671 0.6498 0.6817 0.5993]]\n",
      "[[0.5654 0.67   0.6724 0.6699 0.6241 0.6364]\n",
      " [0.5605 0.6681 0.6842 0.6602 0.6811 0.63  ]\n",
      " [0.6216 0.7101 0.7113 0.6905 0.7142 0.6452]\n",
      " [0.6091 0.7062 0.6947 0.6712 0.6807 0.6391]]\n",
      "[ 0.18667611  2.46455249 -0.10897908  4.6780713 ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "base = '''0.5582\n",
    "0.6655\n",
    "0.6665\n",
    "0.6419\n",
    "0.6780\n",
    "0.6248\n",
    "0.5378\n",
    "0.6559\n",
    "0.6642\n",
    "0.6430\n",
    "0.6723\n",
    "0.6194\n",
    "0.6206\n",
    "0.7144\n",
    "0.7158\n",
    "0.6890\n",
    "0.7129\n",
    "0.6451\n",
    "0.5621\n",
    "0.6676\n",
    "0.6671\n",
    "0.6498\n",
    "0.6817\n",
    "0.5993'''\n",
    "ichm ='''0.5654\n",
    "0.6700\n",
    "0.6724\n",
    "0.6699\n",
    "0.6241\n",
    "0.6364\n",
    "0.5605\n",
    "0.6681\n",
    "0.6842\n",
    "0.6602\n",
    "0.6811\n",
    "0.6300\n",
    "0.6216\n",
    "0.7101\n",
    "0.7113\n",
    "0.6905\n",
    "0.7142\n",
    "0.6452\n",
    "0.6091\n",
    "0.7062\n",
    "0.6947\n",
    "0.6712\n",
    "0.6807\n",
    "0.6391'''\n",
    "\n",
    "\n",
    "base = np.array([float(i) for i in base.split('\\n')]).reshape(4,6)\n",
    "ichm = np.array([float(i) for i in ichm.split('\\n')]).reshape(4,6)\n",
    "\n",
    "def get_improve(base, ichm):\n",
    "    return (ichm-base)/base*100\n",
    "improve = get_improve(base, ichm)\n",
    "improve = np.mean(improve, axis=1)\n",
    "print(base)\n",
    "print(ichm)\n",
    "print(improve)\n",
    "\n",
    "# print(improve)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "random_tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
